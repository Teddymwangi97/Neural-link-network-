{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7efd936",
   "metadata": {},
   "source": [
    "# first we instal the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef734e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.21.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.26.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.14.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f54c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow_addons in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (0.21.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5b2f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (2.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd32f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary modules to process our excel file\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3276b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dde0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f8e5824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pc\\\\Desktop\\\\CHM\\\\data science\\\\data science group project'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47112240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66024e93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S/N</th>\n",
       "      <th>AGE (YRS)</th>\n",
       "      <th>GES. AT BOOKING (WEEK)</th>\n",
       "      <th>GES. AT DELIVERY (WEEK)</th>\n",
       "      <th>BOOKING WEIGHT (KG)</th>\n",
       "      <th>NO OF ANC ATTENDED</th>\n",
       "      <th>IPTS RECEIVED</th>\n",
       "      <th>PVC</th>\n",
       "      <th>PARITY</th>\n",
       "      <th>TYPE OF HEMATINIC RECEIVED</th>\n",
       "      <th>...</th>\n",
       "      <th>TYPE OF LABOUR</th>\n",
       "      <th>MODE OF DELIVERY</th>\n",
       "      <th>FETAL WEIGHT (KG)</th>\n",
       "      <th>FETAL SEX</th>\n",
       "      <th>APGAR SCORES AT 1 MINUTE</th>\n",
       "      <th>APGAR SCORES AT 5 MINUTES</th>\n",
       "      <th>LENGTH OF HOSPITAL</th>\n",
       "      <th>FETAL OUTCOME</th>\n",
       "      <th>MATERNAL OUTCOME</th>\n",
       "      <th>NEED FOR  SPECIAL BABY CARE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>368</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>369</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>370</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>371</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>372</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S/N  AGE (YRS)  GES. AT BOOKING (WEEK)  GES. AT DELIVERY (WEEK)  \\\n",
       "0      1         32                       7                       38   \n",
       "1      2         26                      10                       38   \n",
       "2      3         24                      11                       38   \n",
       "3      4         29                      10                       38   \n",
       "4      5         23                      11                       38   \n",
       "..   ...        ...                     ...                      ...   \n",
       "367  368         26                      22                       34   \n",
       "368  369         26                      15                       38   \n",
       "369  370         32                      24                       36   \n",
       "370  371         25                      20                       36   \n",
       "371  372         24                      20                       36   \n",
       "\n",
       "     BOOKING WEIGHT (KG)  NO OF ANC ATTENDED  IPTS RECEIVED  PVC  PARITY  \\\n",
       "0                   57.0                   6              1   32       9   \n",
       "1                   51.0                   6              2   32      35   \n",
       "2                   51.0                   6              2   32      35   \n",
       "3                   51.0                   6              2   32      35   \n",
       "4                   61.0                   9              3    0      20   \n",
       "..                   ...                 ...            ...  ...     ...   \n",
       "367                 65.0                   5              1    0      17   \n",
       "368                 65.0                   8              3   35      17   \n",
       "369                 64.0                   6              2   36      17   \n",
       "370                 54.0                   6              1    0      35   \n",
       "371                 54.0                   6              2   32      35   \n",
       "\n",
       "     TYPE OF HEMATINIC RECEIVED  ...  TYPE OF LABOUR  MODE OF DELIVERY  \\\n",
       "0                             1  ...               4                 1   \n",
       "1                             1  ...               4                 4   \n",
       "2                             1  ...               4                 4   \n",
       "3                             1  ...               4                 4   \n",
       "4                             1  ...               4                 4   \n",
       "..                          ...  ...             ...               ...   \n",
       "367                           1  ...               4                 5   \n",
       "368                           1  ...               3                 6   \n",
       "369                           1  ...               0                 5   \n",
       "370                           1  ...               4                 5   \n",
       "371                           1  ...               4                 5   \n",
       "\n",
       "     FETAL WEIGHT (KG)  FETAL SEX  APGAR SCORES AT 1 MINUTE  \\\n",
       "0                  2.5          2                         9   \n",
       "1                  3.0          0                        10   \n",
       "2                  3.0          2                         9   \n",
       "3                  3.0          2                         9   \n",
       "4                  2.9          2                         6   \n",
       "..                 ...        ...                       ...   \n",
       "367                2.2          0                         3   \n",
       "368                2.5          2                         3   \n",
       "369                3.0          0                         3   \n",
       "370                2.5          2                         3   \n",
       "371                2.7          0                         3   \n",
       "\n",
       "     APGAR SCORES AT 5 MINUTES  LENGTH OF HOSPITAL  FETAL OUTCOME  \\\n",
       "0                            5                   4          Alive   \n",
       "1                            2                   4          Alive   \n",
       "2                            5                   4          Alive   \n",
       "3                            5                   4          Alive   \n",
       "4                           20                   4          Alive   \n",
       "..                         ...                 ...            ...   \n",
       "367                         20                   5          Alive   \n",
       "368                         20                   7          Alive   \n",
       "369                         20                   6          Alive   \n",
       "370                          5                   8          Alive   \n",
       "371                         20                   8          Alive   \n",
       "\n",
       "    MATERNAL OUTCOME NEED FOR  SPECIAL BABY CARE  \n",
       "0              Alive                          No  \n",
       "1              Alive                          No  \n",
       "2              Alive                          No  \n",
       "3              Alive                          No  \n",
       "4              Alive                          No  \n",
       "..               ...                         ...  \n",
       "367            Alive                          No  \n",
       "368            Alive                         Yes  \n",
       "369            Alive                         Yes  \n",
       "370            Alive                         Yes  \n",
       "371            Alive                         Yes  \n",
       "\n",
       "[372 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First task is to import the raw Excel file for processing purpose\n",
    "filename = r'c:\\\\Users\\\\pc\\\\Desktop\\\\CHM\\\\data science\\\\data science group project\\\\Student_copy_Medical_Data_v4.xlsx'\n",
    "\n",
    "initial_df = pd.read_excel(filename, sheet_name='Sheet1')\n",
    "\n",
    "initial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a663a8",
   "metadata": {},
   "source": [
    "'''cleaning the data and checking for nan values'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1214dca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tS/N              : 0 NaN Values\n",
      "\tAGE (YRS)        : 0 NaN Values\n",
      "\tGES. AT BOOKING (WEEK): 0 NaN Values\n",
      "\tGES. AT DELIVERY (WEEK): 0 NaN Values\n",
      "\tBOOKING WEIGHT (KG): 0 NaN Values\n",
      "\tNO OF ANC ATTENDED: 0 NaN Values\n",
      "\tIPTS RECEIVED    : 0 NaN Values\n",
      "\tPVC              : 0 NaN Values\n",
      "\tPARITY           : 0 NaN Values\n",
      "\tTYPE OF HEMATINIC RECEIVED: 0 NaN Values\n",
      "\tMARITAL STATUS   : 0 NaN Values\n",
      "\tTYPE OF LABOUR   : 0 NaN Values\n",
      "\tMODE OF DELIVERY : 0 NaN Values\n",
      "\tFETAL WEIGHT (KG): 0 NaN Values\n",
      "\tFETAL SEX        : 0 NaN Values\n",
      "\tAPGAR SCORES AT 1 MINUTE: 0 NaN Values\n",
      "\tAPGAR SCORES AT 5 MINUTES: 0 NaN Values\n",
      "\tLENGTH OF HOSPITAL: 0 NaN Values\n",
      "\tFETAL OUTCOME    : 0 NaN Values\n",
      "\tMATERNAL OUTCOME : 0 NaN Values\n",
      "\tNEED FOR  SPECIAL BABY CARE: 0 NaN Values\n"
     ]
    }
   ],
   "source": [
    "# Identifiying columns with Nan Values\n",
    "for cols in initial_df.columns:\n",
    "    print(f'\\t{cols:<17}: {initial_df[cols].isna().sum()} NaN Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb23d39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372 entries, 0 to 371\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   S/N                          372 non-null    int64  \n",
      " 1   AGE (YRS)                    372 non-null    int64  \n",
      " 2   GES. AT BOOKING (WEEK)       372 non-null    int64  \n",
      " 3   GES. AT DELIVERY (WEEK)      372 non-null    int64  \n",
      " 4   BOOKING WEIGHT (KG)          372 non-null    float64\n",
      " 5   NO OF ANC ATTENDED           372 non-null    int64  \n",
      " 6   IPTS RECEIVED                372 non-null    int64  \n",
      " 7   PVC                          372 non-null    int64  \n",
      " 8   PARITY                       372 non-null    int64  \n",
      " 9   TYPE OF HEMATINIC RECEIVED   372 non-null    int64  \n",
      " 10  MARITAL STATUS               372 non-null    int64  \n",
      " 11  TYPE OF LABOUR               372 non-null    int64  \n",
      " 12  MODE OF DELIVERY             372 non-null    int64  \n",
      " 13  FETAL WEIGHT (KG)            372 non-null    float64\n",
      " 14  FETAL SEX                    372 non-null    int64  \n",
      " 15  APGAR SCORES AT 1 MINUTE     372 non-null    int64  \n",
      " 16  APGAR SCORES AT 5 MINUTES    372 non-null    int64  \n",
      " 17  LENGTH OF HOSPITAL           372 non-null    int64  \n",
      " 18  FETAL OUTCOME                372 non-null    object \n",
      " 19  MATERNAL OUTCOME             372 non-null    object \n",
      " 20  NEED FOR  SPECIAL BABY CARE  372 non-null    object \n",
      "dtypes: float64(2), int64(16), object(3)\n",
      "memory usage: 61.2+ KB\n"
     ]
    }
   ],
   "source": [
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85146fa",
   "metadata": {},
   "source": [
    "'''now we need to convert our 'strings/object' that is in our data into numbers for our model to read it'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f947fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Categorical Data into Numerical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in initial_df.columns:\n",
    "    if initial_df[column].dtype == 'object':\n",
    "        initial_df[column] = le.fit_transform(initial_df[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdacb44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372 entries, 0 to 371\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   S/N                          372 non-null    int64  \n",
      " 1   AGE (YRS)                    372 non-null    int64  \n",
      " 2   GES. AT BOOKING (WEEK)       372 non-null    int64  \n",
      " 3   GES. AT DELIVERY (WEEK)      372 non-null    int64  \n",
      " 4   BOOKING WEIGHT (KG)          372 non-null    float64\n",
      " 5   NO OF ANC ATTENDED           372 non-null    int64  \n",
      " 6   IPTS RECEIVED                372 non-null    int64  \n",
      " 7   PVC                          372 non-null    int64  \n",
      " 8   PARITY                       372 non-null    int64  \n",
      " 9   TYPE OF HEMATINIC RECEIVED   372 non-null    int64  \n",
      " 10  MARITAL STATUS               372 non-null    int64  \n",
      " 11  TYPE OF LABOUR               372 non-null    int64  \n",
      " 12  MODE OF DELIVERY             372 non-null    int64  \n",
      " 13  FETAL WEIGHT (KG)            372 non-null    float64\n",
      " 14  FETAL SEX                    372 non-null    int64  \n",
      " 15  APGAR SCORES AT 1 MINUTE     372 non-null    int64  \n",
      " 16  APGAR SCORES AT 5 MINUTES    372 non-null    int64  \n",
      " 17  LENGTH OF HOSPITAL           372 non-null    int64  \n",
      " 18  FETAL OUTCOME                372 non-null    int32  \n",
      " 19  MATERNAL OUTCOME             372 non-null    int32  \n",
      " 20  NEED FOR  SPECIAL BABY CARE  372 non-null    int32  \n",
      "dtypes: float64(2), int32(3), int64(16)\n",
      "memory usage: 56.8 KB\n"
     ]
    }
   ],
   "source": [
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38470160",
   "metadata": {},
   "source": [
    "'''reducing the size of our data to int16 and float16'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e378214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['S/N', 'AGE (YRS)', 'GES. AT BOOKING (WEEK)', 'GES. AT DELIVERY (WEEK)',\n",
      "       'NO OF ANC ATTENDED', 'IPTS RECEIVED', 'PVC', 'PARITY',\n",
      "       'TYPE OF HEMATINIC RECEIVED', 'MARITAL STATUS', 'TYPE OF LABOUR',\n",
      "       'MODE OF DELIVERY', 'FETAL SEX', 'APGAR SCORES AT 1 MINUTE',\n",
      "       'APGAR SCORES AT 5 MINUTES', 'LENGTH OF HOSPITAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "int64_List =initial_df.select_dtypes(include = \"int64\").columns\n",
    "print (int64_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eff0ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372 entries, 0 to 371\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   S/N                          372 non-null    int16  \n",
      " 1   AGE (YRS)                    372 non-null    int16  \n",
      " 2   GES. AT BOOKING (WEEK)       372 non-null    int16  \n",
      " 3   GES. AT DELIVERY (WEEK)      372 non-null    int16  \n",
      " 4   BOOKING WEIGHT (KG)          372 non-null    float64\n",
      " 5   NO OF ANC ATTENDED           372 non-null    int16  \n",
      " 6   IPTS RECEIVED                372 non-null    int16  \n",
      " 7   PVC                          372 non-null    int16  \n",
      " 8   PARITY                       372 non-null    int16  \n",
      " 9   TYPE OF HEMATINIC RECEIVED   372 non-null    int16  \n",
      " 10  MARITAL STATUS               372 non-null    int16  \n",
      " 11  TYPE OF LABOUR               372 non-null    int16  \n",
      " 12  MODE OF DELIVERY             372 non-null    int16  \n",
      " 13  FETAL WEIGHT (KG)            372 non-null    float64\n",
      " 14  FETAL SEX                    372 non-null    int16  \n",
      " 15  APGAR SCORES AT 1 MINUTE     372 non-null    int16  \n",
      " 16  APGAR SCORES AT 5 MINUTES    372 non-null    int16  \n",
      " 17  LENGTH OF HOSPITAL           372 non-null    int16  \n",
      " 18  FETAL OUTCOME                372 non-null    int32  \n",
      " 19  MATERNAL OUTCOME             372 non-null    int32  \n",
      " 20  NEED FOR  SPECIAL BABY CARE  372 non-null    int32  \n",
      "dtypes: float64(2), int16(16), int32(3)\n",
      "memory usage: 21.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Converting the data to minimize size\n",
    "for column in int64_List:\n",
    "    initial_df[column] = initial_df[column].astype (\"int16\")\n",
    "\n",
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7be72a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FETAL OUTCOME', 'MATERNAL OUTCOME', 'NEED FOR  SPECIAL BABY CARE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "int32_List =initial_df.select_dtypes(include = \"int32\").columns\n",
    "print (int32_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36b5c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372 entries, 0 to 371\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   S/N                          372 non-null    int16  \n",
      " 1   AGE (YRS)                    372 non-null    int16  \n",
      " 2   GES. AT BOOKING (WEEK)       372 non-null    int16  \n",
      " 3   GES. AT DELIVERY (WEEK)      372 non-null    int16  \n",
      " 4   BOOKING WEIGHT (KG)          372 non-null    float64\n",
      " 5   NO OF ANC ATTENDED           372 non-null    int16  \n",
      " 6   IPTS RECEIVED                372 non-null    int16  \n",
      " 7   PVC                          372 non-null    int16  \n",
      " 8   PARITY                       372 non-null    int16  \n",
      " 9   TYPE OF HEMATINIC RECEIVED   372 non-null    int16  \n",
      " 10  MARITAL STATUS               372 non-null    int16  \n",
      " 11  TYPE OF LABOUR               372 non-null    int16  \n",
      " 12  MODE OF DELIVERY             372 non-null    int16  \n",
      " 13  FETAL WEIGHT (KG)            372 non-null    float64\n",
      " 14  FETAL SEX                    372 non-null    int16  \n",
      " 15  APGAR SCORES AT 1 MINUTE     372 non-null    int16  \n",
      " 16  APGAR SCORES AT 5 MINUTES    372 non-null    int16  \n",
      " 17  LENGTH OF HOSPITAL           372 non-null    int16  \n",
      " 18  FETAL OUTCOME                372 non-null    int16  \n",
      " 19  MATERNAL OUTCOME             372 non-null    int16  \n",
      " 20  NEED FOR  SPECIAL BABY CARE  372 non-null    int16  \n",
      "dtypes: float64(2), int16(19)\n",
      "memory usage: 19.7 KB\n"
     ]
    }
   ],
   "source": [
    "for column in int32_List:\n",
    "    initial_df[column] = initial_df[column].astype (\"int16\")\n",
    "\n",
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b8fe891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BOOKING WEIGHT (KG)', 'FETAL WEIGHT (KG)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# float64 is too big, reduce it to float16, \n",
    "\n",
    "float64_List =initial_df.select_dtypes(include = \"float64\").columns\n",
    "print (float64_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "878b7d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372 entries, 0 to 371\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   S/N                          372 non-null    int16  \n",
      " 1   AGE (YRS)                    372 non-null    int16  \n",
      " 2   GES. AT BOOKING (WEEK)       372 non-null    int16  \n",
      " 3   GES. AT DELIVERY (WEEK)      372 non-null    int16  \n",
      " 4   BOOKING WEIGHT (KG)          372 non-null    float16\n",
      " 5   NO OF ANC ATTENDED           372 non-null    int16  \n",
      " 6   IPTS RECEIVED                372 non-null    int16  \n",
      " 7   PVC                          372 non-null    int16  \n",
      " 8   PARITY                       372 non-null    int16  \n",
      " 9   TYPE OF HEMATINIC RECEIVED   372 non-null    int16  \n",
      " 10  MARITAL STATUS               372 non-null    int16  \n",
      " 11  TYPE OF LABOUR               372 non-null    int16  \n",
      " 12  MODE OF DELIVERY             372 non-null    int16  \n",
      " 13  FETAL WEIGHT (KG)            372 non-null    float16\n",
      " 14  FETAL SEX                    372 non-null    int16  \n",
      " 15  APGAR SCORES AT 1 MINUTE     372 non-null    int16  \n",
      " 16  APGAR SCORES AT 5 MINUTES    372 non-null    int16  \n",
      " 17  LENGTH OF HOSPITAL           372 non-null    int16  \n",
      " 18  FETAL OUTCOME                372 non-null    int16  \n",
      " 19  MATERNAL OUTCOME             372 non-null    int16  \n",
      " 20  NEED FOR  SPECIAL BABY CARE  372 non-null    int16  \n",
      "dtypes: float16(2), int16(19)\n",
      "memory usage: 15.4 KB\n"
     ]
    }
   ],
   "source": [
    "for column in float64_List:\n",
    "    initial_df[column] = initial_df[column].astype (\"float16\")\n",
    "\n",
    "initial_df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e513c",
   "metadata": {},
   "source": [
    "'''creating a features Variables columns for our model to consider those columns inorder \n",
    "    to give us an output'''    # note we want 'NEED FOR  SPECIAL BABY CARE' to be our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5657a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGE (YRS)',\n",
       " 'GES. AT BOOKING (WEEK)',\n",
       " 'GES. AT DELIVERY (WEEK)',\n",
       " 'BOOKING WEIGHT (KG)',\n",
       " 'NO OF ANC ATTENDED',\n",
       " 'IPTS RECEIVED',\n",
       " 'PVC',\n",
       " 'PARITY',\n",
       " 'TYPE OF HEMATINIC RECEIVED',\n",
       " 'MARITAL STATUS',\n",
       " 'TYPE OF LABOUR',\n",
       " 'MODE OF DELIVERY',\n",
       " 'FETAL WEIGHT (KG)',\n",
       " 'FETAL SEX',\n",
       " 'APGAR SCORES AT 1 MINUTE',\n",
       " 'APGAR SCORES AT 5 MINUTES',\n",
       " 'LENGTH OF HOSPITAL',\n",
       " 'FETAL OUTCOME',\n",
       " 'MATERNAL OUTCOME']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting feature importances\n",
    "features = initial_df.columns.tolist()\n",
    "features = features[1:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35c408f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our X and y variables\n",
    "X = initial_df[features] \n",
    "y = initial_df['NEED FOR  SPECIAL BABY CARE']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eba8b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets(70% and 30%)respectively    STEP 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee1d9299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigating some few data    the number of columns\n",
    "\n",
    "input_features = X_train.shape[1]\n",
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e8dfb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196    2\n",
       "19     1\n",
       "356    1\n",
       "79     1\n",
       "167    1\n",
       "      ..\n",
       "71     1\n",
       "106    1\n",
       "270    1\n",
       "348    1\n",
       "102    1\n",
       "Name: NEED FOR  SPECIAL BABY CARE, Length: 260, dtype: int16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84a3cc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values using set\n",
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e4936b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number unique values using set\n",
    "output_options = len(set(y_train))\n",
    "output_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ca526e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af4a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Creating, compiling, and fitting our neural network model      \n",
    "# output_options = 10\n",
    "\n",
    "ai_model = tf.keras.Sequential()\n",
    "ai_model.add(tf.keras.layers.Dense(input_features)) # 784 input features\n",
    "ai_model.add(tf.keras.layers.Dense(output_options, activation='sigmoid')) #Output options and activation\n",
    "#It can be relu, softmax, softsign, tanh, selu, elu, exponential, PRelu, LeakyReLu\n",
    "\n",
    "# Compiling the neural network model\n",
    "ai_model.compile(\n",
    "    optimizer='adam', # Others are: 'SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl', 'AdamW', 'Adafactor'\n",
    "    loss='sparse_categorical_crossentropy', # Others are: categorical_crossentropy, poisson, kl_divergence, binary_crossentropy\n",
    "    metrics=['accuracy'] # Others are: binary_accuracy, categorical_accuracy, sparse_categorical_accuracy \n",
    ")\n",
    "\n",
    "# Fitting the model with train data\n",
    "training_times = 10\n",
    "ai_model.fit(X_train,y_train, epochs=training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e76139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating with Test Data\n",
    "ai_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2fe057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLING SCALLING TO IMPROVE OUR ACCURACY   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scal_Xtrain = scaler.fit_transform(X_train)\n",
    "scal_Xtest = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b48ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating, compiling, and fitting our neural network model\n",
    "# output_options = 10\n",
    "\n",
    "ai_model = tf.keras.Sequential()\n",
    "ai_model.add(tf.keras.layers.Dense(input_features)) # 784 input features\n",
    "ai_model.add(tf.keras.layers.Dense(output_options, activation='sigmoid')) #Output options and activation\n",
    "#It can be relu, softmax, softsign, tanh, selu, elu, exponential, PRelu, LeakyReLu\n",
    "\n",
    "# Compiling the neural network model\n",
    "ai_model.compile(\n",
    "    optimizer='adamax', # Others are: 'SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl', 'AdamW', 'Adafactor'\n",
    "    loss='sparse_categorical_crossentropy', # Others are: categorical_crossentropy, poisson, kl_divergence, binary_crossentropy\n",
    "    metrics=['accuracy'] # Others are: binary_accuracy, categorical_accuracy, sparse_categorical_accuracy \n",
    ")\n",
    "\n",
    "# Fitting the model with train data\n",
    "training_times = 10\n",
    "ai_model.fit(scal_Xtrain,y_train, epochs=training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating with Test Data\n",
    "ai_model.evaluate(scal_Xtest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d647b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using my Best optimizer (Adam)\n",
    "# Creating, compiling, and fitting our neural network model\n",
    "# output_options = 10\n",
    "\n",
    "ai_model = tf.keras.Sequential()\n",
    "ai_model.add(tf.keras.layers.Dense(input_features)) # 784 input features\n",
    "ai_model.add(tf.keras.layers.Dense(output_options, activation='sigmoid')) #Output options and activation\n",
    "#It can be relu, softmax, softsign, tanh, selu, elu, exponential, PRelu, LeakyReLu\n",
    "\n",
    "# Compiling the neural network model\n",
    "ai_model.compile(\n",
    "    optimizer='adam', # Others are: 'SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl', 'AdamW', 'Adafactor'\n",
    "    loss='sparse_categorical_crossentropy', # Others are: categorical_crossentropy, poisson, kl_divergence, binary_crossentropy\n",
    "    metrics=['accuracy'] # Others are: binary_accuracy, categorical_accuracy, sparse_categorical_accuracy \n",
    ")\n",
    "\n",
    "# Fitting the model with train data\n",
    "training_times = 10\n",
    "ai_model.fit(scal_Xtrain,y_train, epochs=training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating with Test Data\n",
    "ai_model.evaluate(scal_Xtest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7814aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predicted test values\n",
    "y_predicted = ai_model.predict(scal_Xtest)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74323131",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the actual predictions rather than probability\n",
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Confusion Matrix\n",
    "confusion_matrix_v1 = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\n",
    "confusion_matrix_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed423c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn libary\n",
    "import seaborn as sn\n",
    "plt.figure(figsize=(7,5))\n",
    "sn.heatmap(confusion_matrix_v1, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91652c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an intermediate Layer to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadca682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using my Best optimizer (Adam)\n",
    "# Creating, compiling, and fitting our neural network model\n",
    "# output_options = 10\n",
    "# Intermediate neurons = 394\n",
    "\n",
    "ai_model = tf.keras.Sequential()\n",
    "ai_model.add(tf.keras.layers.Dense(input_features)) # 784 input features\n",
    "ai_model.add(tf.keras.layers.Dense(392, activation='leaky_relu')) # Intermediate layer\n",
    "ai_model.add(tf.keras.layers.Dense(output_options, activation='sigmoid')) #Output activation\n",
    "#It can be relu, softmax, softsign, tanh, selu, elu, exponential, PRelu, LeakyReLu\n",
    "\n",
    "# Compiling the neural network model\n",
    "ai_model.compile(\n",
    "    optimizer='adam', # Others are: 'SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl', 'AdamW', 'Adafactor'\n",
    "    loss='sparse_categorical_crossentropy', # Others are: categorical_crossentropy, poisson, kl_divergence, binary_crossentropy\n",
    "    metrics=['accuracy'] # Others are: binary_accuracy, categorical_accuracy, sparse_categorical_accuracy \n",
    ")\n",
    "\n",
    "# Fitting the model with train data\n",
    "training_times = 10\n",
    "ai_model.fit(scal_Xtrain,y_train, epochs=training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating with Test Data\n",
    "# batch_size is what ratio of the actual test data should be used\n",
    "ai_model.evaluate(scal_Xtest, y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a717f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predicted test values\n",
    "y_predicted = ai_model.predict(scal_Xtest)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80398c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the actual y_test value\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf131b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the actual predictions rather than probability\n",
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efde095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Confusion Matrix\n",
    "confusion_matrix_v2 = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\n",
    "confusion_matrix_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn libary for v2 matrix\n",
    "import seaborn as sn\n",
    "plt.figure(figsize=(7,5))\n",
    "sn.heatmap(confusion_matrix_v2, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ada79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using feature engineering for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting only the useful columns in our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_columns = ['AGE (YRS)','FETAL OUTCOME', 'LENGTH OF HOSPITAL','MATERNAL OUTCOME']  \n",
    "\n",
    "selected_features = [feature for feature in features if feature in selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076389bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our X and y variables\n",
    "X_2 = initial_df[selected_features] \n",
    "y_2 = initial_df['NEED FOR  SPECIAL BABY CARE']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dff019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets(70% and 30%)respectively    STEP 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69004030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating some few data\n",
    "\n",
    "input_2_features = X_2_train.shape[1]\n",
    "input_2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2859431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number unique values using set\n",
    "output_2_options = len(set(y_2_train))\n",
    "output_2_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9693f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating, compiling, and fitting our neural network model\n",
    "# output_options = 10\n",
    "\n",
    "ai_model = tf.keras.Sequential()\n",
    "ai_model.add(tf.keras.layers.Dense(input_2_features)) # 784 input features\n",
    "ai_model.add(tf.keras.layers.Dense(output_2_options, activation='sigmoid')) #Output options and activation\n",
    "#It can be relu, softmax, softsign, tanh, selu, elu, exponential, PRelu, LeakyReLu\n",
    "\n",
    "# Compiling the neural network model\n",
    "ai_model.compile(\n",
    "    optimizer='adam', # Others are: 'SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl', 'AdamW', 'Adafactor'\n",
    "    loss='binary_crossentropy', # Others are: categorical_crossentropy, poisson, kl_divergence, binary_crossentropy\n",
    "    metrics=['accuracy'] # Others are: binary_accuracy, categorical_accuracy, sparse_categorical_accuracy \n",
    ")\n",
    "\n",
    "# Fitting the model with train data\n",
    "training_times = 10\n",
    "ai_model.fit(X_2_train,y_2_train, epochs=training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating with Test Data\n",
    "ai_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b687060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#appling scaling to our selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scal_X_2_train = scaler.fit_transform(X_2_train)\n",
    "scal_X_2_test = scaler.transform(X_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating, compiling, and fitting our neural network model\n",
    "# output_options = 10\n",
    "\n",
    "ai_model = tf.keras.Sequential()\n",
    "ai_model.add(tf.keras.layers.Dense(input_2_features)) # 784 input features\n",
    "ai_model.add(tf.keras.layers.Dense(output_2_options, activation='sigmoid')) #Output options and activation\n",
    "#It can be relu, softmax, softsign, tanh, selu, elu, exponential, PRelu, LeakyReLu\n",
    "\n",
    "# Compiling the neural network model\n",
    "ai_model.compile(\n",
    "    optimizer='adamax', # Others are: 'SGD','RMSprop','Adam','Adadelta','Adagrad','Adamax','Nadam','Ftrl', 'AdamW', 'Adafactor'\n",
    "    loss='sparse_categorical_crossentropy', # Others are: categorical_crossentropy, poisson, kl_divergence, binary_crossentropy\n",
    "    metrics=['accuracy'] # Others are: binary_accuracy, categorical_accuracy, sparse_categorical_accuracy \n",
    ")\n",
    "\n",
    "# Fitting the model with train data\n",
    "training_times = 10\n",
    "ai_model.fit(scal_X_2_train,y_2_train, epochs=training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating with Test Data\n",
    "ai_model.evaluate(scal_X_2_test, y_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predicted test values\n",
    "y_2_predicted = ai_model.predict(scal_X_2_test)\n",
    "y_2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14015ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_2_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the actual y_test value\n",
    "y_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the actual predictions rather than probability\n",
    "y_2_predicted_labels = [np.argmax(i) for i in y_2_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Confusion Matrix\n",
    "confusion_matrix_v3 = tf.math.confusion_matrix(labels=y_2_test, predictions=y_2_predicted_labels)\n",
    "confusion_matrix_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2392f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn libary\n",
    "import seaborn as sn\n",
    "plt.figure(figsize=(7,5))\n",
    "sn.heatmap(confusion_matrix_v3, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn libary for v1 matrix\n",
    "import seaborn as sn\n",
    "plt.figure(figsize=(7,5))\n",
    "sn.heatmap(confusion_matrix_v2, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn libary for v1 matrix\n",
    "import seaborn as sn\n",
    "plt.figure(figsize=(7,5))\n",
    "sn.heatmap(confusion_matrix_v1, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbebeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce170233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d7bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb67ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387831e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a74d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6aa108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48707f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10eaaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32de61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd8ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b241eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c27ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92057871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73289c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d1393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bfe44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22334f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88885cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37712c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b98744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a51167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e2991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2022.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
